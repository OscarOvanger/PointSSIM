{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the experiment Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "from Functions import *\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to parent directory\n",
    "os.chdir('..')\n",
    "# From the parent directory, load the images\n",
    "curved_straight = np.load(r'Binary_images\\curved_straight_images.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curved_data = curved_straight['curved']\n",
    "straight_data = curved_straight['straight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load the first 50 .png images from the 'Mask' folder\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Directory containing the .png files\n",
    "mask_dir = 'Mask'\n",
    "\n",
    "# Initialize an empty list to store the numpy arrays\n",
    "data_mask = []\n",
    "\n",
    "# Get the list of all files in the directory\n",
    "all_files = os.listdir(mask_dir)\n",
    "\n",
    "# Filter out only .png files and sort them\n",
    "png_files = sorted([file for file in all_files if file.endswith('.png')])\n",
    "\n",
    "# Loop over the first 50 .png files\n",
    "for file in png_files[:50]:\n",
    "    # Create the full path to the file\n",
    "    file_path = os.path.join(mask_dir, file)\n",
    "    \n",
    "    # Open the image file\n",
    "    with Image.open(file_path) as img:\n",
    "        # Convert the image to a numpy array\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # Convert all non-zero values to 1\n",
    "        img_array[img_array != 0] = 1\n",
    "        \n",
    "        # Append the numpy array to the list\n",
    "        data_mask.append(img_array)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nature_data = np.load('Nature_data.npy')\n",
    "ragnar_data = np.load('ragnar_data.npy')\n",
    "TGRF_data = np.load('TGRF_data.npy')\n",
    "TGRF_data_small = np.load('TGRF_data_small.npy')\n",
    "TGRF_data_complex = np.load('TGRF_data_complex.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "#for i in range(10):\n",
    "#    ax[i].imshow(Nature_data[i], cmap='gray')\n",
    "#    ax[i].axis('off')\n",
    "#plt.show()\n",
    "fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(ragnar_data[i], cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(TGRF_data[i], cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(TGRF_data_small[i], cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(TGRF_data_complex[i], cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n",
    "#fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "#for i in range(10):\n",
    "#    ax[i].imshow(data_mask[i], cmap='gray')\n",
    "#    ax[i].axis('off')\n",
    "#plt.show()\n",
    "fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(curved_data[i], cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(straight_data[i], cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the different vectors\n",
    "#OM_vector_ragnar = np.load('OM_vector_ragnar.npy')\n",
    "#OM_vector_TGRF = np.load('OM_vector_TGRF.npy')\n",
    "#OM_vector_TGRF_small = np.load('OM_vector_TGRF_small.npy')\n",
    "#OM_vector_TGRF_complex = np.load('OM_vector_TGRF_complex.npy')\n",
    "os.chdir('..')\n",
    "os.chdir('Vectors')\n",
    "OR_vector_ragnar = np.load('OR_vector_ragnar.npy')\n",
    "OR_vector_TGRF = np.load('OR_vector_TGRF.npy')\n",
    "OR_vector_TGRF_small = np.load('OR_vector_TGRF_small.npy')\n",
    "OR_vector_TGRF_complex = np.load('OR_vector_TGRF_complex.npy')\n",
    "OR_vector_curved = np.load('OR_vector_curved.npy')\n",
    "OR_vector_straight = np.load('OR_vector_straight.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMi_vector_ragnar = []\n",
    "OMi_vector_TGRF = []\n",
    "OMi_vector_TGRF_small = []\n",
    "OMi_vector_TGRF_complex = []\n",
    "OMi_vector_curved = []\n",
    "OMi_vector_straight = []\n",
    "os.chdir('..')\n",
    "os.chdir('Code')\n",
    "from Reduced_functions import oscar_micky_vec\n",
    "for j in range(5):\n",
    "    OMi_vector_curved_curr = []\n",
    "    OMi_vector_straight_curr = []\n",
    "    OMi_vector_ragnar_curr = []\n",
    "    OMi_vector_TGRF_curr = []\n",
    "    OMi_vector_TGRF_small_curr = []\n",
    "    OMi_vector_TGRF_complex_curr = []\n",
    "    for i in range(50):\n",
    "        OMi_vector_curved_curr.append(oscar_micky_vec(curved_data[i]))\n",
    "        OMi_vector_straight_curr.append(oscar_micky_vec(straight_data[i]))\n",
    "        OMi_vector_ragnar_curr.append(oscar_micky_vec(ragnar_data[i]))\n",
    "        OMi_vector_TGRF_curr.append(oscar_micky_vec(TGRF_data[i]))\n",
    "        OMi_vector_TGRF_small_curr.append(oscar_micky_vec(TGRF_data_small[i]))\n",
    "        OMi_vector_TGRF_complex_curr.append(oscar_micky_vec(TGRF_data_complex[i]))\n",
    "    OMi_vector_curved.append(OMi_vector_curved_curr)\n",
    "    OMi_vector_straight.append(OMi_vector_straight_curr)\n",
    "    OMi_vector_ragnar.append(OMi_vector_ragnar_curr)\n",
    "    OMi_vector_TGRF.append(OMi_vector_TGRF_curr)\n",
    "    OMi_vector_TGRF_small.append(OMi_vector_TGRF_small_curr)\n",
    "    OMi_vector_TGRF_complex.append(OMi_vector_TGRF_complex_curr)\n",
    "OMi_all_vecs = [OMi_vector_ragnar, OMi_vector_TGRF, OMi_vector_TGRF_small, OMi_vector_TGRF_complex, OMi_vector_curved, OMi_vector_straight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the vectors\n",
    "np.save('OMi_vector_ragnar.npy', OMi_vector_ragnar)\n",
    "np.save('OMi_vector_TGRF.npy', OMi_vector_TGRF)\n",
    "np.save('OMi_vector_TGRF_small.npy', OMi_vector_TGRF_small)\n",
    "np.save('OMi_vector_TGRF_complex.npy', OMi_vector_TGRF_complex)\n",
    "np.save('OMi_vector_curved.npy', OMi_vector_curved)\n",
    "np.save('OMi_vector_straight.npy', OMi_vector_straight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_ragnar = []\n",
    "image_paths_TGRF = []\n",
    "image_paths_TGRF_small = []\n",
    "image_paths_TGRF_complex = []\n",
    "image_paths_curved = []\n",
    "image_paths_straight = []\n",
    "for i in range(50):\n",
    "    image_paths_ragnar.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\ragnar_data' + str(i) + r'.png')\n",
    "    image_paths_TGRF.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\TGRF_data' + str(i) + r'.png')\n",
    "    image_paths_TGRF_small.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\TGRF_data_small' + str(i) + r'.png')\n",
    "    image_paths_TGRF_complex.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\TGRF_complex' + str(i) + r'.png')\n",
    "    image_paths_curved.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\curved_' + str(i) + r'.png')\n",
    "    image_paths_straight.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\straight_' + str(i) + r'.png')\n",
    "image_paths = [image_paths_ragnar, image_paths_TGRF, image_paths_TGRF_small, image_paths_TGRF_complex, image_paths_curved, image_paths_straight]\n",
    "datanames = ['Ragnar', 'TGRF', 'TGRF_small', 'TGRF_complex', 'Curved', 'Straight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(OMi_vector_ragnar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMi_all_vecs = [OMi_vector_ragnar[0], OMi_vector_TGRF[0], OMi_vector_TGRF_small[0], OMi_vector_TGRF_complex[0], OMi_vector_curved[0], OMi_vector_straight[0]]\n",
    "portnr,volume = scatter_plot_with_images_update(OMi_all_vecs,image_paths,datanames,filename='OMi_scatter_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMi_all_vecs = [OMi_vector_ragnar[1], OMi_vector_TGRF[1], OMi_vector_TGRF_small[1], OMi_vector_TGRF_complex[1], OMi_vector_curved[1], OMi_vector_straight[1]]\n",
    "portnr,volume = scatter_plot_with_images_update(OMi_all_vecs,image_paths,datanames,filename='OMi_scatter_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMi_all_vecs = [OMi_vector_ragnar[2], OMi_vector_TGRF[2], OMi_vector_TGRF_small[2], OMi_vector_TGRF_complex[2], OMi_vector_curved[2], OMi_vector_straight[2]]\n",
    "portnr,volume = scatter_plot_with_images_update(OMi_all_vecs,image_paths,datanames,filename='OMi_scatter_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMi_all_vecs = [OMi_vector_ragnar[3], OMi_vector_TGRF[3], OMi_vector_TGRF_small[3], OMi_vector_TGRF_complex[3], OMi_vector_curved[3], OMi_vector_straight[3]]\n",
    "portnr,volume = scatter_plot_with_images_update(OMi_all_vecs,image_paths,datanames,filename='OMi_scatter_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMi_all_vecs = [OMi_vector_ragnar[4], OMi_vector_TGRF[4], OMi_vector_TGRF_small[4], OMi_vector_TGRF_complex[4], OMi_vector_curved[4], OMi_vector_straight[4]]\n",
    "portnr,volume = scatter_plot_with_images_update(OMi_all_vecs,image_paths,datanames,filename='OMi_scatter_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_all_vecs = [OR_vector_ragnar, OR_vector_TGRF, OR_vector_TGRF_small, OR_vector_TGRF_complex, OR_vector_curved, OR_vector_straight]\n",
    "datanames = ['Ragnar', 'TGRF', 'TGRF_small', 'TGRF_complex', 'Curved', 'Straight']\n",
    "portnr,volume = scatter_plot_with_images_update(OR_all_vecs,image_paths,datanames,filename='OR_scatter_plot.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(vec1,vec2):\n",
    "    comp = []\n",
    "    for i in range(len(vec1)):\n",
    "        calc = (vec1[i]-vec2[i])**2/np.max([vec1[i],vec2[i]])**2\n",
    "        comp.append(calc)\n",
    "    comp = np.array(comp)\n",
    "    return np.mean(comp)\n",
    "\n",
    "# Compare all the vectors in OM,OR and OO from different data sets\n",
    "vecs_compared_OR = np.zeros((21,2500))\n",
    "vecs_compared_OMi_0 = np.zeros((21,2500))\n",
    "vecs_compared_OMi_1 = np.zeros((21,2500))\n",
    "vecs_compared_OMi_2 = np.zeros((21,2500))\n",
    "vecs_compared_OMi_3 = np.zeros((21,2500))\n",
    "vecs_compared_OMi_4 = np.zeros((21,2500))\n",
    "k = 0\n",
    "for i in range(6):\n",
    "    for j in range(i,6):\n",
    "        h = 0\n",
    "        l = 0\n",
    "        for vec1 in OR_all_vecs[i]:\n",
    "            for vec2 in OR_all_vecs[j]:\n",
    "                vecs_compared_OR[k,int(h*50 + l)] = comparison(vec1,vec2)\n",
    "                l += 1\n",
    "            h += 1\n",
    "            l = 0\n",
    "        h = 0\n",
    "        l = 0\n",
    "        OMi_all_vecs = [OMi_vector_ragnar[0], OMi_vector_TGRF[0], OMi_vector_TGRF_small[0], OMi_vector_TGRF_complex[0], OMi_vector_curved[0], OMi_vector_straight[0]]\n",
    "        for vec1 in OMi_all_vecs[i]:\n",
    "            for vec2 in OMi_all_vecs[j]:\n",
    "                vecs_compared_OMi_0[k,int(h*50 + l)] = comparison(vec1,vec2)\n",
    "                l += 1\n",
    "            h += 1\n",
    "            l = 0\n",
    "        h = 0\n",
    "        l = 0\n",
    "        OMi_all_vecs = [OMi_vector_ragnar[1], OMi_vector_TGRF[1], OMi_vector_TGRF_small[1], OMi_vector_TGRF_complex[1], OMi_vector_curved[1], OMi_vector_straight[1]]\n",
    "        for vec1 in OMi_all_vecs[i]:\n",
    "            for vec2 in OMi_all_vecs[j]:\n",
    "                vecs_compared_OMi_1[k,int(h*50 + l)] = comparison(vec1,vec2)\n",
    "                l += 1\n",
    "            h += 1\n",
    "            l = 0\n",
    "        h = 0\n",
    "        l = 0\n",
    "        OMi_all_vecs = [OMi_vector_ragnar[2], OMi_vector_TGRF[2], OMi_vector_TGRF_small[2], OMi_vector_TGRF_complex[2], OMi_vector_curved[2], OMi_vector_straight[2]]\n",
    "        for vec1 in OMi_all_vecs[i]:\n",
    "            for vec2 in OMi_all_vecs[j]:\n",
    "                vecs_compared_OMi_2[k,int(h*50 + l)] = comparison(vec1,vec2)\n",
    "                l += 1\n",
    "            h += 1\n",
    "            l = 0\n",
    "        h = 0\n",
    "        l = 0\n",
    "        OMi_all_vecs = [OMi_vector_ragnar[3], OMi_vector_TGRF[3], OMi_vector_TGRF_small[3], OMi_vector_TGRF_complex[3], OMi_vector_curved[3], OMi_vector_straight[3]]\n",
    "        for vec1 in OMi_all_vecs[i]:\n",
    "            for vec2 in OMi_all_vecs[j]:\n",
    "                vecs_compared_OMi_3[k,int(h*50 + l)] = comparison(vec1,vec2)\n",
    "                l += 1\n",
    "            h += 1\n",
    "            l = 0\n",
    "        h = 0\n",
    "        l = 0\n",
    "        OMi_all_vecs = [OMi_vector_ragnar[4], OMi_vector_TGRF[4], OMi_vector_TGRF_small[4], OMi_vector_TGRF_complex[4], OMi_vector_curved[4], OMi_vector_straight[4]]\n",
    "        for vec1 in OMi_all_vecs[i]:\n",
    "            for vec2 in OMi_all_vecs[j]:\n",
    "                vecs_compared_OMi_4[k,int(h*50 + l)] = comparison(vec1,vec2)\n",
    "                l += 1\n",
    "            h += 1\n",
    "            l = 0\n",
    "        k += 1\n",
    "\n",
    "#Measure the structural similarity between the binary images\n",
    "all_data = [ragnar_data, TGRF_data, TGRF_data_complex]\n",
    "similarity = np.zeros((6,2500))\n",
    "k = 0\n",
    "for i in range(3):\n",
    "    for j in range(i,3):\n",
    "        h = 0\n",
    "        l = 0\n",
    "        for img1 in all_data[i]:\n",
    "            for img2 in all_data[j]:\n",
    "                similarity[k,int(h*50 + l)] = ssim(img1.astype(np.float64),img2.astype(np.float64),full=True,data_range = img1.max() - img1.min())[0]\n",
    "                l += 1\n",
    "            h += 1\n",
    "            l = 0\n",
    "        k += 1\n",
    "\n",
    "#Measure the structural similarity between the binary images\n",
    "all_data = [curved_data, straight_data]\n",
    "similarity_2 = np.zeros((3,2500))\n",
    "k = 0\n",
    "for i in range(2):\n",
    "    for j in range(i,2):\n",
    "        h = 0\n",
    "        l = 0\n",
    "        for img1 in all_data[i]:\n",
    "            for img2 in all_data[j]:\n",
    "                similarity_2[k,int(h*50 + l)] = ssim(img1.astype(np.float64),img2.astype(np.float64),full=True,data_range = img1.max() - img1.min())[0]\n",
    "                l += 1\n",
    "            h += 1\n",
    "            l = 0\n",
    "        k += 1\n",
    "\n",
    "['Ragnar', 'TGRF', 'TGRF_small', 'TGRF_complex', 'Curved', 'Straight']\n",
    "# Give a boxplot of the comparison\n",
    "fig, ax = plt.subplots(1,8,figsize=(32,8))\n",
    "ax[0].boxplot(1-vecs_compared_OR.T)\n",
    "ax[0].set_title('OR')\n",
    "ax[0].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[0].set_ylabel('Comparison')\n",
    "ax[1].boxplot(1-vecs_compared_OMi_0.T)\n",
    "ax[1].set_title('OMi_0')\n",
    "ax[1].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[1].set_ylabel('Comparison')\n",
    "ax[2].boxplot(1-vecs_compared_OMi_1.T)\n",
    "ax[2].set_title('OMi_1')\n",
    "ax[2].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[2].set_ylabel('Comparison')\n",
    "ax[3].boxplot(1-vecs_compared_OMi_2.T)\n",
    "ax[3].set_title('OMi_2')\n",
    "ax[3].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[3].set_ylabel('Comparison')\n",
    "ax[4].boxplot(1-vecs_compared_OMi_3.T)\n",
    "ax[4].set_title('OMi_3')\n",
    "ax[4].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[4].set_ylabel('Comparison')\n",
    "ax[5].boxplot(1-vecs_compared_OMi_4.T)\n",
    "ax[5].set_title('OMi_4')\n",
    "ax[5].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[5].set_ylabel('Comparison')\n",
    "ax[6].boxplot(similarity.T)\n",
    "ax[6].set_title('SSIM')\n",
    "ax[6].set_xticklabels(['RvR','RvT','RvTc','TvT','TvTc','TcvsTc'])\n",
    "ax[6].set_ylabel('SSIM')\n",
    "#ax[7].boxplot(similarity_2.T)\n",
    "#ax[7].set_title('SSIM')\n",
    "#ax[7].set_xticklabels(['RvR','RvT','RvTc','TvT','TvTc','TcvsTc'])\n",
    "#ax[7].set_ylabel('SSIM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,7,figsize=(70,10))\n",
    "ax[0].boxplot(1-vecs_compared_OR.T)\n",
    "ax[0].set_title('OR')\n",
    "ax[0].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[0].set_ylabel('Comparison')\n",
    "ax[1].boxplot(1-vecs_compared_OMi_0.T)\n",
    "ax[1].set_title('OMi_0')\n",
    "ax[1].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[1].set_ylabel('Comparison')\n",
    "ax[2].boxplot(1-vecs_compared_OMi_1.T)\n",
    "ax[2].set_title('OMi_1')\n",
    "ax[2].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[2].set_ylabel('Comparison')\n",
    "ax[3].boxplot(1-vecs_compared_OMi_2.T)\n",
    "ax[3].set_title('OMi_2')\n",
    "ax[3].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[3].set_ylabel('Comparison')\n",
    "ax[4].boxplot(1-vecs_compared_OMi_3.T)\n",
    "ax[4].set_title('OMi_3')\n",
    "ax[4].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[4].set_ylabel('Comparison')\n",
    "ax[5].boxplot(1-vecs_compared_OMi_4.T)\n",
    "ax[5].set_title('OMi_4')\n",
    "ax[5].set_xticklabels(['RvR','RvT','RvTs','RvTc','RvC','RvS','TvT','TvTs','TvTc','TvC','TvS','TsvTc','TsvTs','TsvC','TsvS','TcvTc','TcvC','TcvS','CvC','CvS','SvS'])\n",
    "ax[5].set_ylabel('Comparison')\n",
    "ax[6].boxplot(similarity.T)\n",
    "ax[6].set_title('SSIM')\n",
    "ax[6].set_xticklabels(['RvR','RvT','RvTc','TvT','TvTc','TcvsTc'])\n",
    "ax[6].set_ylabel('SSIM')\n",
    "#ax[7].boxplot(similarity_2.T)\n",
    "#ax[7].set_title('SSIM')\n",
    "#ax[7].set_xticklabels(['RvR','RvT','RvTc','TvT','TvTc','TcvsTc'])\n",
    "#ax[7].set_ylabel('SSIM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the vectors for the new data\n",
    "#OM_vector_curved = []\n",
    "#OM_vector_straight = []\n",
    "OR_vector_curved = []\n",
    "OR_vector_straight = []\n",
    "OMi_vector_ragnar = []\n",
    "OMi_vector_TGRF = []\n",
    "OMi_vector_TGRF_small = []\n",
    "OMi_vector_TGRF_complex = []\n",
    "OMi_vector_curved = []\n",
    "OMi_vector_straight = []\n",
    "for i in range(50):\n",
    "    #OM_vector_curved.append(oscar_mike_vec(curved_data[i]))\n",
    "    #OM_vector_straight.append(oscar_mike_vec(straight_data[i]))\n",
    "    OR_vector_curved.append(oscar_ragnar_vec(curved_data[i]))\n",
    "    OR_vector_straight.append(oscar_ragnar_vec(straight_data[i]))\n",
    "    OMi_vector_curved.append(oscar_micky_vec(data_mask[i]))\n",
    "    OMi_vector_straight.append(oscar_micky_vec(data_mask[i]))\n",
    "    OMi_vector_ragnar.append(oscar_micky_vec(ragnar_data[i]))\n",
    "    OMi_vector_TGRF.append(oscar_micky_vec(TGRF_data[i]))\n",
    "    OMi_vector_TGRF_small.append(oscar_micky_vec(TGRF_data_small[i]))\n",
    "    OMi_vector_TGRF_complex.append(oscar_micky_vec(TGRF_data_complex[i]))\n",
    "\n",
    "# Save the data as npy files\n",
    "#np.save('OM_vector_curved', OM_vector_curved)\n",
    "#np.save('OM_vector_straight', OM_vector_straight)\n",
    "np.save('OR_vector_curved', OR_vector_curved)\n",
    "np.save('OR_vector_straight', OR_vector_straight)\n",
    "np.save('OMi_vector_curved', OMi_vector_curved)\n",
    "np.save('OMi_vector_straight', OMi_vector_straight)\n",
    "np.save('OMi_vector_ragnar', OMi_vector_ragnar)\n",
    "np.save('OMi_vector_TGRF', OMi_vector_TGRF)\n",
    "np.save('OMi_vector_TGRF_small', OMi_vector_TGRF_small)\n",
    "np.save('OMi_vector_TGRF_complex', OMi_vector_TGRF_complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Oscar vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OM_all_vecs = [np.load('OM_vector_ragnar.npy'), np.load('OM_vector_TGRF.npy'), np.load('OM_vector_TGRF_small.npy'), np.load('OM_vector_TGRF_complex.npy')]\n",
    "OR_all_vecs = [np.load('OR_vector_ragnar.npy'), np.load('OR_vector_TGRF.npy'), np.load('OR_vector_TGRF_small.npy'), np.load('OR_vector_TGRF_complex.npy'), np.load('OR_vector_curved.npy'), np.load('OR_vector_straight.npy')]\n",
    "OMi_all_vecs = [np.load('OMi_vector_ragnar.npy'), np.load('OMi_vector_TGRF.npy'), np.load('OMi_vector_TGRF_small.npy'), np.load('OMi_vector_TGRF_complex.npy'), np.load('OMi_vector_curved.npy'), np.load('OMi_vector_straight.npy')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Oscar Oscar vector for 50 samples of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_ragnar = []\n",
    "image_paths_TGRF = []\n",
    "image_paths_TGRF_small = []\n",
    "image_paths_TGRF_complex = []\n",
    "image_paths_curved = []\n",
    "image_paths_straight = []\n",
    "for i in range(50):\n",
    "    image_paths_ragnar.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\ragnar_data' + str(i) + r'.png')\n",
    "    image_paths_TGRF.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\TGRF_data' + str(i) + r'.png')\n",
    "    image_paths_TGRF_small.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\TGRF_data_small' + str(i) + r'.png')\n",
    "    image_paths_TGRF_complex.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\TGRF_complex' + str(i) + r'.png')\n",
    "    image_paths_curved.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\curved_' + str(i) + r'.png')\n",
    "    image_paths_straight.append(r'C:\\Users\\oo4663\\OneDrive - NTNU\\PhD\\Paper_3\\Experiment\\Binary_images\\straight_' + str(i) + r'.png')\n",
    "image_paths = [image_paths_ragnar, image_paths_TGRF, image_paths_TGRF_small, image_paths_TGRF_complex, image_paths_curved, image_paths_straight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanames = ['Ragnar', 'TGRF', 'TGRF_small', 'TGRF_complex', 'Curved', 'Straight']\n",
    "portnr = scatter_plot_with_images(OR_all_vecs,image_paths,datanames,filename='OR_scatter_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portnr = scatter_plot_with_images(OMi_all_vecs,image_paths,datanames,filename='OMi_scatter_plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "# Creating a dictionary of the features\n",
    "features = {\n",
    "    'pic_intensity': pic_intesity,\n",
    "    'anc_intensity': anc_intensity,\n",
    "    'obj_intensity': obj_intensity,\n",
    "    'anc_intensity_div_pix_intensity': anc_intensity_div_pix_intensity,\n",
    "    'anc_dist_obj': anc_dist_obj,\n",
    "    'anc_dist_var': anc_dist_var\n",
    "}\n",
    "\n",
    "def normalize_features(features):\n",
    "    # Flatten, find min and max, scale features\n",
    "    flattened = np.array(features).reshape(-1)\n",
    "    min_val = np.min(flattened)\n",
    "    max_val = np.max(flattened)\n",
    "    scaled = (np.array(features) - min_val) / (max_val - min_val)\n",
    "    return [tuple(row) for row in scaled]\n",
    "\n",
    "# Normalize each feature\n",
    "normalized_features = {\n",
    "    'pic_intensity': normalize_features(pic_intesity),\n",
    "    'anc_intensity': normalize_features(anc_intensity),\n",
    "    'obj_intensity': normalize_features(obj_intensity),\n",
    "    'anc_intensity_div_pix_intensity': normalize_features(anc_intensity_div_pix_intensity),\n",
    "    'anc_dist_obj': normalize_features(anc_dist_obj),\n",
    "    'anc_dist_var': normalize_features(anc_dist_var)\n",
    "}\n",
    "\n",
    "# Dataset names and colors\n",
    "dataset_names = ['Pneumonia', 'Breast', 'Ragnar', 'TGRF']\n",
    "colors = ['red', 'blue', 'green', 'yellow']\n",
    "\n",
    "# Get all combinations of three features\n",
    "feature_combinations = list(combinations(features.keys(), 3))\n",
    "normalized_feature_combinations = list(combinations(normalized_features.keys(), 3))\n",
    "# Set up interactive plotting\n",
    "#plt.ion()  # Turn on interactive mode\n",
    "\n",
    "# For each combination, create a plot\n",
    "'''\n",
    "for combo in feature_combinations:\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Add data points\n",
    "    for i, dataset_name in enumerate(dataset_names):\n",
    "        x_values = [features[combo[0]][j][i] for j in range(50)]\n",
    "        y_values = [features[combo[1]][j][i] for j in range(50)]\n",
    "        z_values = [features[combo[2]][j][i] for j in range(50)]\n",
    "        ax.scatter(x_values, y_values, z_values, color=colors[i], label=dataset_name)\n",
    "\n",
    "    ax.set_xlabel(combo[0])\n",
    "    ax.set_ylabel(combo[1])\n",
    "    ax.set_zlabel(combo[2])\n",
    "    ax.legend()\n",
    "    ax.set_title(f'3D Scatter Plot: {combo[0]}, {combo[1]}, {combo[2]}')\n",
    "    plt.show()\n",
    "    #input(\"Press Enter to continue to the next plot...\") \n",
    "'''\n",
    "\n",
    "for combo in normalized_feature_combinations:\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Add data points\n",
    "    for i, dataset_name in enumerate(dataset_names):\n",
    "        x_values = [normalized_features[combo[0]][j][i] for j in range(50)]\n",
    "        y_values = [normalized_features[combo[1]][j][i] for j in range(50)]\n",
    "        z_values = [normalized_features[combo[2]][j][i] for j in range(50)]\n",
    "        ax.scatter(x_values, y_values, z_values, color=colors[i], label=dataset_name)\n",
    "\n",
    "    ax.set_xlabel(combo[0])\n",
    "    ax.set_ylabel(combo[1])\n",
    "    ax.set_zlabel(combo[2])\n",
    "    ax.legend()\n",
    "    ax.set_title(f'3D Scatter Plot: {combo[0]}, {combo[1]}, {combo[2]}')\n",
    "    plt.show()\n",
    "    #input(\"Press Enter to continue to the next plot...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Function to normalize the features\n",
    "def normalize_features(features):\n",
    "    # Flatten, find min and max, scale features\n",
    "    flattened = np.array(features).reshape(-1)\n",
    "    min_val = np.min(flattened)\n",
    "    max_val = np.max(flattened)\n",
    "    scaled = (np.array(features) - min_val) / (max_val - min_val)\n",
    "    return [tuple(row) for row in scaled]\n",
    "\n",
    "# Normalize each feature\n",
    "normalized_features = {\n",
    "    'pic_intensity': normalize_features(pic_intesity),\n",
    "    'anc_intensity': normalize_features(anc_intensity),\n",
    "    'obj_intensity': normalize_features(obj_intensity),\n",
    "    'anc_intensity_div_pix_intensity': normalize_features(anc_intensity_div_pix_intensity),\n",
    "    'anc_dist_obj': normalize_features(anc_dist_obj),\n",
    "    'anc_dist_var': normalize_features(anc_dist_var)\n",
    "}\n",
    "\n",
    "# Calculate distances\n",
    "def calculate_distances(data):\n",
    "    inner_distances = []\n",
    "    outer_distances = []\n",
    "    for i in range(len(data[0])):\n",
    "        for j in range(i + 1, len(data[0])):\n",
    "            inner_distances.append(np.linalg.norm(np.array(data[:, i]) - np.array(data[:, j])))\n",
    "            for k in range(4):\n",
    "                for l in range(k + 1, 4):\n",
    "                    outer_distances.append(np.linalg.norm(np.array(data[k, :]) - np.array(data[l, :])))\n",
    "    return np.mean(inner_distances), np.mean(outer_distances)\n",
    "\n",
    "# Try all combinations of three features\n",
    "best_score = 0\n",
    "best_combination = None\n",
    "for combination in itertools.combinations(normalized_features.keys(), 3):\n",
    "    combined_data = np.array([[normalized_features[feat][i][k] for feat in combination] for i in range(50) for k in range(4)])\n",
    "    combined_data = combined_data.reshape(4, 50, 3)  # Shape (dataset, samples, features)\n",
    "    mean_inner, mean_outer = calculate_distances(combined_data)\n",
    "    #score = mean_outer / mean_inner\n",
    "    score = mean_outer\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_combination = combination\n",
    "\n",
    "print(\"Best feature combination:\", best_combination)\n",
    "print(\"Score (higher is better):\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from itertools import combinations\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Assuming normalized_features contains your normalized data and feature names\n",
    "feature_keys = list(normalized_features.keys())\n",
    "\n",
    "# Prepare the combinations\n",
    "combinations = list(combinations(feature_keys, 3))\n",
    "\n",
    "# Dataset colors and labels (customize as needed)\n",
    "colors = ['red', 'blue', 'green', 'yellow']\n",
    "dataset_labels = ['Dataset 1', 'Dataset 2', 'Dataset 3', 'Dataset 4']\n",
    "\n",
    "# Create plots for each combination\n",
    "for combo in combinations:\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    combined_data = np.array([[normalized_features[feat][i][k] for feat in combo] for i in range(50) for k in range(4)])\n",
    "    combined_data = combined_data.reshape(4, 50, 3)  # Reshape to (dataset, samples, features)\n",
    "    \n",
    "    # Plot each dataset\n",
    "    scatters = []\n",
    "    for i in range(4):\n",
    "        xs, ys, zs = combined_data[i].T  # Transpose to separate columns\n",
    "        sc = ax.scatter(xs, ys, zs, color=colors[i], label=f'{dataset_labels[i]}: {combo}')\n",
    "        scatters.append(sc)\n",
    "\n",
    "    # Setting labels based on selected features\n",
    "    ax.set_xlabel(f'{combo[0]}')\n",
    "    ax.set_ylabel(f'{combo[1]}')\n",
    "    ax.set_zlabel(f'{combo[2]}')\n",
    "    ax.set_title(f'3D Plot of Features: {combo}')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    # Animation function to rotate the plot\n",
    "    \"\"\"\n",
    "    def update(frame, ax, fig):\n",
    "        ax.view_init(elev=10, azim=frame)\n",
    "\n",
    "    ani = FuncAnimation(fig, update, fargs=(ax, fig), frames=np.arange(0, 360, 2), interval=50)\n",
    "\n",
    "    # Save animation\n",
    "    filename = f'3d_plot_{\"_\".join(combo)}.gif'\n",
    "    ani.save(filename, writer='Pillow', fps=20)\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"Animations created for all combinations.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize each dimension to 0-1\n",
    "oscar_vec_Pneumonia = np.array(oscar_vec_Pneumonia)\n",
    "oscar_vec_Breast = np.array(oscar_vec_Breast)\n",
    "oscar_vec_ragnar = np.array(oscar_vec_ragnar)\n",
    "oscar_vec_TGRF = np.array(oscar_vec_TGRF)\n",
    "max_val_dim_0 = np.max([oscar_vec_Pneumonia[:,0], oscar_vec_Breast[:,0], oscar_vec_ragnar[:,0], oscar_vec_TGRF[:,0]])\n",
    "max_val_dim_1 = np.max([oscar_vec_Pneumonia[:,1], oscar_vec_Breast[:,1], oscar_vec_ragnar[:,1], oscar_vec_TGRF[:,1]])\n",
    "max_val_dim_2 = np.max([oscar_vec_Pneumonia[:,2], oscar_vec_Breast[:,2], oscar_vec_ragnar[:,2], oscar_vec_TGRF[:,2]])\n",
    "oscar_vec_Pneumonia[:,0] = oscar_vec_Pneumonia[:,0]/max_val_dim_0\n",
    "oscar_vec_Pneumonia[:,1] = oscar_vec_Pneumonia[:,1]/max_val_dim_1\n",
    "oscar_vec_Pneumonia[:,2] = oscar_vec_Pneumonia[:,2]/max_val_dim_2\n",
    "oscar_vec_Breast[:,0] = oscar_vec_Breast[:,0]/max_val_dim_0\n",
    "oscar_vec_Breast[:,1] = oscar_vec_Breast[:,1]/max_val_dim_1\n",
    "oscar_vec_Breast[:,2] = oscar_vec_Breast[:,2]/max_val_dim_2\n",
    "oscar_vec_ragnar[:,0] = oscar_vec_ragnar[:,0]/max_val_dim_0\n",
    "oscar_vec_ragnar[:,1] = oscar_vec_ragnar[:,1]/max_val_dim_1\n",
    "oscar_vec_ragnar[:,2] = oscar_vec_ragnar[:,2]/max_val_dim_2\n",
    "oscar_vec_TGRF[:,0] = oscar_vec_TGRF[:,0]/max_val_dim_0\n",
    "oscar_vec_TGRF[:,1] = oscar_vec_TGRF[:,1]/max_val_dim_1\n",
    "oscar_vec_TGRF[:,2] = oscar_vec_TGRF[:,2]/max_val_dim_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Add data points\n",
    "sc = []\n",
    "for i, dataset_name in enumerate(dataset_names):\n",
    "    x_values = [normalized_features[normalized_feature_combinations[14][0]][j][i] for j in range(50)]\n",
    "    y_values = [normalized_features[normalized_feature_combinations[14][1]][j][i] for j in range(50)]\n",
    "    z_values = [normalized_features[normalized_feature_combinations[14][2]][j][i] for j in range(50)]\n",
    "    sc.append(ax.scatter(x_values, y_values, z_values, color=colors[i], label=dataset_name))\n",
    "\n",
    "ax.set_xlabel(normalized_feature_combinations[14][0])\n",
    "ax.set_ylabel(normalized_feature_combinations[14][1])\n",
    "ax.set_zlabel(normalized_feature_combinations[14][2])\n",
    "ax.legend()\n",
    "ax.set_title(f'3D Scatter Plot: {normalized_feature_combinations[14][0]}, {normalized_feature_combinations[14][1]}, {normalized_feature_combinations[14][2]}')\n",
    "# Animation function to rotate the plot\n",
    "def update(frame):\n",
    "    ax.view_init(elev=10, azim=frame)\n",
    "    return sc[0], sc[1], sc[2], sc[3]\n",
    "\n",
    "# Animate\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(0, 360, 2), interval=50, blit=True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Save animation\n",
    "ani.save('3d_plot_all_data_diff_comb.gif', writer='Pillow', fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a 3D plot of the Oscar vectors\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot each dataset\n",
    "oscar_array_Pneumonia = np.array(oscar_vec_Pneumonia)\n",
    "oscar_array_TGRF = np.array(oscar_vec_TGRF)\n",
    "oscar_array_Breast = np.array(oscar_vec_Breast)\n",
    "oscar_array_ragnar = np.array(oscar_vec_ragnar)\n",
    "sc1 = ax.scatter(oscar_array_Pneumonia[:,0], oscar_array_Pneumonia[:,1], oscar_array_Pneumonia[:,2],label='Ragnar data',c='r')\n",
    "sc2 = ax.scatter(oscar_array_Breast[:,0],oscar_array_Breast[:,1],oscar_array_Breast[:,2],label='Breast data',c='b')\n",
    "sc3 = ax.scatter(oscar_array_ragnar[:,0],oscar_array_ragnar[:,1],oscar_array_ragnar[:,2],label='Pneumonia data',c='g')\n",
    "sc4 = ax.scatter(oscar_array_TGRF[:,0],oscar_array_TGRF[:,1],oscar_array_TGRF[:,2],label='TGRF data',c='y')\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Nr. of anchors / Nr. of pixels')\n",
    "ax.set_ylabel('Variance of nr. of anchors in objects')\n",
    "ax.set_zlabel('Average distance between anchors within objects')\n",
    "ax.set_title('3D vector plot of fingerprints')\n",
    "ax.legend()\n",
    "# Animation function to rotate the plot\n",
    "def update(frame):\n",
    "    ax.view_init(elev=10, azim=frame)\n",
    "    return sc1, sc2, sc3, sc4\n",
    "\n",
    "# Animate\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(0, 360, 2), interval=50, blit=True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Save animation\n",
    "ani.save('3d_plot_all_data.gif', writer='Pillow', fps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do SSIM calculations between the datasets and within the datasets\n",
    "ssim_vals_inner = np.zeros((3,50,50))\n",
    "ssim_vals_between = np.zeros((3,50,50))\n",
    "all_data = [Pneumonia_data,Breast_data,TGRF_data_small]\n",
    "for i in range(50):\n",
    "    for j in range(50):\n",
    "        for k in range(3):\n",
    "            image1 = all_data[k][i].astype(int)\n",
    "            image2 = all_data[k][j].astype(int)\n",
    "            ssim_vals_inner[k,i,j] = ssim(image1,image2, data_range=image1.max() - image1.min())\n",
    "        numbers = [0,1,2]\n",
    "        combinations = list(itertools.combinations(numbers, 2))\n",
    "        it = 0\n",
    "        for comb in combinations:\n",
    "            image1 = all_data[comb[0]][i].astype(int)\n",
    "            image2 = all_data[comb[1]][j].astype(int)\n",
    "            ssim_vals_between[it,i,j] = ssim(image1,image2, data_range=image1.max() - image1.min())\n",
    "            it += 1\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    dot_product = np.dot(u, v)\n",
    "    norms = np.linalg.norm(u) * np.linalg.norm(v)\n",
    "    return dot_product / norms\n",
    "\n",
    "def adjusted_cosine_similarity(u, v):\n",
    "    return (1 + cosine_similarity(u, v)) / 2\n",
    "\n",
    "# Calculate the euclidean distance between the oscar vectors\n",
    "euclidean_dist_inner = np.zeros((4,50,50))\n",
    "euclidean_dist_between = np.zeros((6,50,50))\n",
    "oscar_array_all = [oscar_array_Pneumonia,oscar_array_Breast,oscar_array_ragnar,oscar_array_TGRF]\n",
    "for i in range(50):\n",
    "    for j in range(50):\n",
    "        for k in range(4):\n",
    "            euclidean_dist_inner[k,i,j] = np.linalg.norm(oscar_array_all[k][i]-oscar_array_all[k][j])\n",
    "        numbers = [0,1,2,3]\n",
    "        combinations = list(itertools.combinations(numbers, 2))\n",
    "        it = 0\n",
    "        for comb in combinations:\n",
    "            euclidean_dist_between[it,i,j] = np.linalg.norm(oscar_array_all[comb[0]][i]-oscar_array_all[comb[1]][j])\n",
    "            it += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot in box plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot([ssim_vals_inner[0].flatten(),ssim_vals_inner[1].flatten(),ssim_vals_inner[2].flatten(),ssim_vals_between[0].flatten(),ssim_vals_between[1].flatten(),ssim_vals_between[2].flatten()])\n",
    "ax.set_xticklabels(['Pneumonia vs Pneumonia','Breast vs Breast','TGRF vs TGRF','Pneumonia vs Breast','Pneumonia vs TGRF','Breast vs TGRF'],fontsize=5)\n",
    "plt.show()\n",
    "\n",
    "# Plot average and standard deviation for euclidean distances\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot([euclidean_dist_inner[0].flatten(),euclidean_dist_inner[1].flatten(),euclidean_dist_inner[2].flatten(),euclidean_dist_inner[3].flatten(),euclidean_dist_between[0].flatten(),euclidean_dist_between[1].flatten(),euclidean_dist_between[2].flatten(),euclidean_dist_between[3].flatten(),euclidean_dist_between[4].flatten(),euclidean_dist_between[5].flatten()])\n",
    "ax.set_xticklabels(['Pneumonia vs Pneumonia','Breast vs Breast','Ragnar vs Ragnar','TGRF vs TGRF','Pneumonia vs Breast','Pneumonia vs Ragnar','Pneumonia vs TGRF','Breast vs Ragnar','Breast vs TGRF','Ragnar vs TGRF'],fontsize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the 2 different anchor points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_custom_pneumonia = []\n",
    "anchor_custom_breast = []\n",
    "anchor_custom_ragnar = []\n",
    "anchor_custom_TGRF = []\n",
    "for i in range(50):\n",
    "    anchor_custom_pneumonia.append(custom_anchors(Pneumonia_data[i]))\n",
    "    anchor_custom_breast.append(custom_anchors(Breast_data[i]))\n",
    "    anchor_custom_ragnar.append(custom_anchors(ragnar_data[i]))\n",
    "    anchor_custom_TGRF.append(custom_anchors(TGRF_data[i]))\n",
    "\n",
    "#anchors_skeleton_pneumonia = []\n",
    "#anchors_skeleton_breast = []\n",
    "#anchors_skeleton_ragnar = []\n",
    "#anchors_skeleton_TGRF = []\n",
    "#for i in range(50):\n",
    "#    anchors_skeleton_pneumonia.append(skeleton_anchors(Pneumonia_data[i]))\n",
    "#    anchors_skeleton_breast.append(skeleton_anchors(Breast_data[i]))\n",
    "#    anchors_skeleton_ragnar.append(skeleton_anchors(ragnar_data[i]))\n",
    "#    anchors_skeleton_TGRF.append(skeleton_anchors(TGRF_data[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(Pneumonia_data[i], cmap='gray')\n",
    "    ax[i].scatter(np.where(anchor_custom_pneumonia[i])[1], np.where(anchor_custom_pneumonia[i])[0], c='r', s=1)\n",
    "    ax[i].axis('off')\n",
    "plt.suptitle('Distance Transform Anchors, Pneumonia Data')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(Pneumonia_data[i], cmap='gray')\n",
    "    ax[i].scatter([hei[1] for hei in anchors_skeleton_pneumonia[i]], [hei[0] for hei in anchors_skeleton_pneumonia[i]], c='r', s=1)\n",
    "    ax[i].axis('off')\n",
    "plt.suptitle('Skeleton Anchors, Pneumonia Data')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(Breast_data[i], cmap='gray')\n",
    "    ax[i].scatter(np.where(anchor_custom_breast[i])[1], np.where(anchor_custom_breast[i])[0], c='r', s=1)\n",
    "    ax[i].axis('off')\n",
    "plt.suptitle('Distance Transform Anchors, Breast Data')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(Breast_data[i], cmap='gray')\n",
    "    ax[i].scatter([hei[1] for hei in anchors_skeleton_breast[i]], [hei[0] for hei in anchors_skeleton_breast[i]], c='r', s=1)\n",
    "    ax[i].axis('off')\n",
    "plt.suptitle('Skeleton Anchors, Breast Data')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(ragnar_data[i], cmap='gray')\n",
    "    ax[i].scatter(np.where(anchor_custom_ragnar[i])[1], np.where(anchor_custom_ragnar[i])[0], c='r', s=1)\n",
    "    ax[i].axis('off')\n",
    "plt.suptitle('Distance Transform Anchors, Ragnar Data')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(ragnar_data[i], cmap='gray')\n",
    "    ax[i].scatter([hei[1] for hei in anchors_skeleton_ragnar[i]], [hei[0] for hei in anchors_skeleton_ragnar[i]], c='r', s=1)\n",
    "    ax[i].axis('off')\n",
    "plt.suptitle('Skeleton Anchors, Ragnar Data')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(TGRF_data[i], cmap='gray')\n",
    "    ax[i].scatter(np.where(anchor_custom_TGRF[i])[1], np.where(anchor_custom_TGRF[i])[0], c='r', s=1)\n",
    "    ax[i].axis('off')\n",
    "plt.suptitle('Distance Transform Anchors, TGRF Data')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(TGRF_data[i], cmap='gray')\n",
    "    ax[i].scatter([hei[1] for hei in anchors_skeleton_TGRF[i]], [hei[0] for hei in anchors_skeleton_TGRF[i]], c='r', s=1)\n",
    "    ax[i].axis('off')\n",
    "plt.suptitle('Skeleton Anchors, TGRF Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Adjacency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change format of anchor points\n",
    "anchors_pneumonia = []\n",
    "anchors_breast = []\n",
    "anchors_ragnar = []\n",
    "anchors_grf = []\n",
    "for j in range(50):\n",
    "    anchors = [(np.where(anchor_custom_pneumonia[j])[0][i],np.where(anchor_custom_pneumonia[j])[1][i]) for i in range(len(np.where(anchor_custom_pneumonia[j])[0]))]\n",
    "    anchors_pneumonia.append(anchors)\n",
    "    anchors = [(np.where(anchor_custom_breast[j])[0][i],np.where(anchor_custom_breast[j])[1][i]) for i in range(len(np.where(anchor_custom_breast[j])[0]))]\n",
    "    anchors_breast.append(anchors)\n",
    "    anchors = [(np.where(anchor_custom_ragnar[j])[0][i],np.where(anchor_custom_ragnar[j])[1][i]) for i in range(len(np.where(anchor_custom_ragnar[j])[0]))]\n",
    "    anchors_ragnar.append(anchors)\n",
    "    anchors = [(np.where(anchor_custom_TGRF[j])[0][i],np.where(anchor_custom_TGRF[j])[1][i]) for i in range(len(np.where(anchor_custom_TGRF[j])[0]))]\n",
    "    anchors_grf.append(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_Pneumonia = []\n",
    "A_Pneumonia = []\n",
    "distances_Breast = []\n",
    "A_Breast = []\n",
    "distances_ragnar = []\n",
    "A_ragnar = []\n",
    "distances_grf = []\n",
    "A_grf = []\n",
    "\n",
    "for i in range(50):\n",
    "    distances = calculate_distance_among_objects(Pneumonia_data[i].astype(bool),anchors_pneumonia[i])\n",
    "    distances_Pneumonia.append(distances)\n",
    "    A_Pneumonia.append(build_adjacency_matrix(anchor_custom_pneumonia[i],distances))\n",
    "    distances = calculate_distance_among_objects(Breast_data[i].astype(bool),anchors_breast[i])\n",
    "    distances_Breast.append(distances)\n",
    "    A_Breast.append(build_adjacency_matrix(anchor_custom_breast[i],distances))\n",
    "    distances = calculate_distance_among_objects(ragnar_data[i].astype(bool),anchors_ragnar[i])\n",
    "    distances_ragnar.append(distances)\n",
    "    A_ragnar.append(build_adjacency_matrix(anchor_custom_ragnar[i],distances))\n",
    "    distances = calculate_distance_among_objects(TGRF_data[i].astype(bool),anchors_grf[i])\n",
    "    distances_grf.append(distances)\n",
    "    A_grf.append(build_adjacency_matrix(anchor_custom_TGRF[i],distances))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TGRF_data[0]\n",
    "anchors = [(np.where(anchor_custom_TGRF[0])[0][i],np.where(anchor_custom_TGRF[0])[1][i]) for i in range(len(np.where(anchor_custom_TGRF[0])[0]))]\n",
    "dists = calculate_distance_among_objects(TGRF_data[0].astype(bool),anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find average distance between anchors\n",
    "import math\n",
    "# Filter out non-finite values\n",
    "finite_distances = [value for value in dists.values() if math.isfinite(value)]\n",
    "average_distance = sum(finite_distances) / len(finite_distances)\n",
    "print(average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do imshow of the first adjacency matrix of each dataset\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 4))\n",
    "ax[0].imshow(A_Pneumonia[0])\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Pneumonia')\n",
    "ax[1].imshow(A_Breast[0])\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Breast')\n",
    "ax[2].imshow(A_ragnar[0])\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('Ragnar')\n",
    "ax[3].imshow(A_grf[0])\n",
    "ax[3].axis('off')\n",
    "ax[3].set_title('TGRF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weight_distribution(A_Pneumonia[:3],'A_Pneumonia')\n",
    "plot_weight_distribution(A_Breast[:3],'A_Breast')\n",
    "plot_weight_distribution(A_ragnar[:3],'A_ragnar')\n",
    "plot_weight_distribution(A_grf[:3],'A_grf')\n",
    "plot_degree_distribution(A_Pneumonia[:3],'A_Pneumonia')\n",
    "plot_degree_distribution(A_Breast[:3],'A_Breast')\n",
    "plot_degree_distribution(A_ragnar[:3],'A_ragnar')\n",
    "plot_degree_distribution(A_grf[:3],'A_grf')\n",
    "plot_eigenvalue_distribution(A_Pneumonia[:3],'A_Pneumonia')\n",
    "plot_eigenvalue_distribution(A_Breast[:3],'A_Breast')\n",
    "plot_eigenvalue_distribution(A_ragnar[:3],'A_ragnar')\n",
    "plot_eigenvalue_distribution(A_grf[:3],'A_grf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
